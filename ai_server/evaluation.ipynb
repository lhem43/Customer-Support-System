{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-02T12:30:04.407629Z",
     "iopub.status.busy": "2025-03-02T12:30:04.407290Z",
     "iopub.status.idle": "2025-03-02T12:30:04.655959Z",
     "shell.execute_reply": "2025-03-02T12:30:04.655275Z",
     "shell.execute_reply.started": "2025-03-02T12:30:04.407602Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"/kaggle/input/multilingual-customer-support-tickets/dataset-tickets-multi-lang-4-20k.csv\")  \n",
    "\n",
    "df_english = df[df[\"language\"] == \"en\"].reset_index(drop=True)\n",
    "\n",
    "df_english = df_english[[\"body\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T12:19:29.431334Z",
     "iopub.status.busy": "2025-03-02T12:19:29.431054Z",
     "iopub.status.idle": "2025-03-02T12:19:29.440029Z",
     "shell.execute_reply": "2025-03-02T12:19:29.439159Z",
     "shell.execute_reply.started": "2025-03-02T12:19:29.431313Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Seeking information on digital strategies that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am contacting you to request information on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dear Customer Support, I am reaching out to in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Inquiring about best practices for securing me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The integration stopped working unexpectedly, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11918</th>\n",
       "      <td>Seeking details on securing medical data using...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11919</th>\n",
       "      <td>Can you provide information on digital strateg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11920</th>\n",
       "      <td>Request for assistance in improving digital ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11921</th>\n",
       "      <td>I am facing integration problems with IFTTT Do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11922</th>\n",
       "      <td>Hello Customer Support, I am inquiring about t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11923 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    body\n",
       "0      Seeking information on digital strategies that...\n",
       "1      I am contacting you to request information on ...\n",
       "2      Dear Customer Support, I am reaching out to in...\n",
       "3      Inquiring about best practices for securing me...\n",
       "4      The integration stopped working unexpectedly, ...\n",
       "...                                                  ...\n",
       "11918  Seeking details on securing medical data using...\n",
       "11919  Can you provide information on digital strateg...\n",
       "11920  Request for assistance in improving digital ma...\n",
       "11921  I am facing integration problems with IFTTT Do...\n",
       "11922  Hello Customer Support, I am inquiring about t...\n",
       "\n",
       "[11923 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T12:20:11.737501Z",
     "iopub.status.busy": "2025-03-02T12:20:11.737168Z",
     "iopub.status.idle": "2025-03-02T12:20:13.232499Z",
     "shell.execute_reply": "2025-03-02T12:20:13.231838Z",
     "shell.execute_reply.started": "2025-03-02T12:20:11.737474Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "paraphrase_pipe = pipeline(\n",
    "    \"text2text-generation\",\n",
    "    model=\"Vamsi/T5_Paraphrase_Paws\",  \n",
    "    tokenizer=\"Vamsi/T5_Paraphrase_Paws\",\n",
    "    device=0 \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T12:29:56.158657Z",
     "iopub.status.busy": "2025-03-02T12:29:56.158317Z",
     "iopub.status.idle": "2025-03-02T12:29:56.165733Z",
     "shell.execute_reply": "2025-03-02T12:29:56.164674Z",
     "shell.execute_reply.started": "2025-03-02T12:29:56.158629Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def paraphrase_text(batch):\n",
    "    paraphrased_bodies = []\n",
    "    \n",
    "    for text in batch[\"body\"]:\n",
    "        results = paraphrase_pipe(\n",
    "            text, \n",
    "            max_length=50, \n",
    "            num_return_sequences=3,  \n",
    "            temperature=0.9,  \n",
    "            top_p=0.85,  \n",
    "            do_sample=True\n",
    "        )\n",
    "        \n",
    "        if isinstance(results, list) and results and isinstance(results[0], dict):\n",
    "            paraphrased_texts = [res[\"generated_text\"] for res in results]\n",
    "        elif isinstance(results, list) and results and isinstance(results[0], str):\n",
    "            paraphrased_texts = results\n",
    "        else:\n",
    "            paraphrased_texts = [str(results)]\n",
    "            \n",
    "        paraphrased_texts = list(set(paraphrased_texts))\n",
    "        \n",
    "        chosen_text = paraphrased_texts[1] if len(paraphrased_texts) > 1 else paraphrased_texts[0]\n",
    "        paraphrased_bodies.append(chosen_text)\n",
    "    \n",
    "    return {\"paraphrased_body\": paraphrased_bodies}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T12:30:08.298726Z",
     "iopub.status.busy": "2025-03-02T12:30:08.298449Z",
     "iopub.status.idle": "2025-03-02T12:30:08.331052Z",
     "shell.execute_reply": "2025-03-02T12:30:08.330173Z",
     "shell.execute_reply.started": "2025-03-02T12:30:08.298705Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "dataset = Dataset.from_pandas(df_english)\n",
    "dataset = dataset.shuffle(seed=40).select(range(len(dataset) - 2000, len(dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T12:30:09.943797Z",
     "iopub.status.busy": "2025-03-02T12:30:09.943374Z",
     "iopub.status.idle": "2025-03-02T12:30:09.948867Z",
     "shell.execute_reply": "2025-03-02T12:30:09.947960Z",
     "shell.execute_reply.started": "2025-03-02T12:30:09.943758Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['body'],\n",
       "    num_rows: 2000\n",
       "})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T12:30:13.217423Z",
     "iopub.status.busy": "2025-03-02T12:30:13.217116Z",
     "iopub.status.idle": "2025-03-02T12:55:55.111547Z",
     "shell.execute_reply": "2025-03-02T12:55:55.110832Z",
     "shell.execute_reply.started": "2025-03-02T12:30:13.217382Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8bb1b9acae24ac9aef458791a5e7767",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_paraphrased = dataset.map(paraphrase_text, batched=True, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T05:44:37.416115Z",
     "iopub.status.busy": "2025-02-24T05:44:37.415828Z",
     "iopub.status.idle": "2025-02-24T05:44:37.421613Z",
     "shell.execute_reply": "2025-02-24T05:44:37.420646Z",
     "shell.execute_reply.started": "2025-02-24T05:44:37.416094Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': 'Dear [Name], thank you for reaching out to our customer support team regarding investment data analysis tools. We would be happy to provide guidance on how to effectively utilize these tools to make informed investment decisions. To better assist you, could you please provide us with information on the specific tools you are currently using and the type of investments you are looking to optimize? This will enable us to provide tailored recommendations. Would prefer to discuss this over the phone, please let us know a suitable time.',\n",
       " 'paraphrased_answer': 'Dear [Name], thank you for reaching out to our customer support team regarding investment data analysis tools . We would be happy to provide guidance on how to effectively use these tools to make informed investment decisions . To better assist you, please provide us with information on the specific tools you are currently using and the type of investments you are looking to optimize , this will enable us to provide tailored recommendations .'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_paraphrased[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T12:59:13.634706Z",
     "iopub.status.busy": "2025-03-02T12:59:13.634334Z",
     "iopub.status.idle": "2025-03-02T12:59:13.644182Z",
     "shell.execute_reply": "2025-03-02T12:59:13.643180Z",
     "shell.execute_reply.started": "2025-03-02T12:59:13.634678Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataset_paraphrased = dataset_paraphrased.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T13:02:29.689091Z",
     "iopub.status.busy": "2025-03-02T13:02:29.688761Z",
     "iopub.status.idle": "2025-03-02T13:02:29.699201Z",
     "shell.execute_reply": "2025-03-02T13:02:29.698381Z",
     "shell.execute_reply.started": "2025-03-02T13:02:29.689065Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>paraphrased_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Can you provide information on optimizing inve...</td>\n",
       "      <td>I am interested to know which tools can help m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am contacting you to inquire about optimizin...</td>\n",
       "      <td>I am contacting you to inquire about optimizin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am contacting you to ask about the analytics...</td>\n",
       "      <td>I am contacting you to ask about the analytics...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Seeking details on securing medical data using...</td>\n",
       "      <td>Seeking details on securing medical data using...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Our hospital systems are facing data security ...</td>\n",
       "      <td>Our hospital systems are facing data security ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>The project management platform has encountere...</td>\n",
       "      <td>The project management platform has encountere...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>I noticed there were unexpected charges on my ...</td>\n",
       "      <td>I noticed that there were unexpected charges o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>Customers are facing challenges integrating Zo...</td>\n",
       "      <td>Customers are facing challenges in integrating...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>I would like to know more about the data analy...</td>\n",
       "      <td>I would like to know more about the data analy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>The investment optimization tool has encounter...</td>\n",
       "      <td>The investment optimization tool has encounter...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   body  \\\n",
       "0     Can you provide information on optimizing inve...   \n",
       "1     I am contacting you to inquire about optimizin...   \n",
       "2     I am contacting you to ask about the analytics...   \n",
       "3     Seeking details on securing medical data using...   \n",
       "4     Our hospital systems are facing data security ...   \n",
       "...                                                 ...   \n",
       "1995  The project management platform has encountere...   \n",
       "1996  I noticed there were unexpected charges on my ...   \n",
       "1997  Customers are facing challenges integrating Zo...   \n",
       "1998  I would like to know more about the data analy...   \n",
       "1999  The investment optimization tool has encounter...   \n",
       "\n",
       "                                       paraphrased_body  \n",
       "0     I am interested to know which tools can help m...  \n",
       "1     I am contacting you to inquire about optimizin...  \n",
       "2     I am contacting you to ask about the analytics...  \n",
       "3     Seeking details on securing medical data using...  \n",
       "4     Our hospital systems are facing data security ...  \n",
       "...                                                 ...  \n",
       "1995  The project management platform has encountere...  \n",
       "1996  I noticed that there were unexpected charges o...  \n",
       "1997  Customers are facing challenges in integrating...  \n",
       "1998  I would like to know more about the data analy...  \n",
       "1999  The investment optimization tool has encounter...  \n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_paraphrased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T05:45:35.509835Z",
     "iopub.status.busy": "2025-02-24T05:45:35.509509Z",
     "iopub.status.idle": "2025-02-24T05:45:35.599065Z",
     "shell.execute_reply": "2025-02-24T05:45:35.598366Z",
     "shell.execute_reply.started": "2025-02-24T05:45:35.509808Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='answers_paraphrased.csv' target='_blank'>answers_paraphrased.csv</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/answers_paraphrased.csv"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_filename = \"answers_paraphrased.csv\"\n",
    "dataset_paraphrased.to_csv(csv_filename, index=False)\n",
    "from IPython.display import FileLink\n",
    "FileLink(csv_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T13:13:01.576031Z",
     "iopub.status.busy": "2025-03-02T13:13:01.575747Z",
     "iopub.status.idle": "2025-03-02T13:13:06.499376Z",
     "shell.execute_reply": "2025-03-02T13:13:06.498458Z",
     "shell.execute_reply.started": "2025-03-02T13:13:01.576011Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "sbert_model = SentenceTransformer(\"/kaggle/input/sbert_v2/transformers/default/1/fine_tuned_kbqa_sbert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T13:13:41.470138Z",
     "iopub.status.busy": "2025-03-02T13:13:41.469832Z",
     "iopub.status.idle": "2025-03-02T13:13:41.474086Z",
     "shell.execute_reply": "2025-03-02T13:13:41.473256Z",
     "shell.execute_reply.started": "2025-03-02T13:13:41.470111Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "original_sentences = dataset_paraphrased[\"body\"].tolist()\n",
    "paraphrased_sentences = dataset_paraphrased[\"paraphrased_body\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T13:14:57.468660Z",
     "iopub.status.busy": "2025-03-02T13:14:57.468269Z",
     "iopub.status.idle": "2025-03-02T13:15:11.965684Z",
     "shell.execute_reply": "2025-03-02T13:15:11.964928Z",
     "shell.execute_reply.started": "2025-03-02T13:14:57.468631Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69cbad875eb74f2cb08940cc58b35e57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e95b4700e5634fdc86709f547b7bcd07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embeddings_original = sbert_model.encode(original_sentences, convert_to_tensor=True)\n",
    "embeddings_paraphrased = sbert_model.encode(paraphrased_sentences, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T13:15:44.331870Z",
     "iopub.status.busy": "2025-03-02T13:15:44.331566Z",
     "iopub.status.idle": "2025-03-02T13:15:44.379550Z",
     "shell.execute_reply": "2025-03-02T13:15:44.378938Z",
     "shell.execute_reply.started": "2025-03-02T13:15:44.331831Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import util\n",
    "cosine_scores = util.cos_sim(embeddings_original, embeddings_paraphrased)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T13:17:22.067997Z",
     "iopub.status.busy": "2025-03-02T13:17:22.067689Z",
     "iopub.status.idle": "2025-03-02T13:17:22.110315Z",
     "shell.execute_reply": "2025-03-02T13:17:22.109364Z",
     "shell.execute_reply.started": "2025-03-02T13:17:22.067974Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "scores = [cosine_scores[i][i].item() for i in range(len(original_sentences))]\n",
    "average_score = sum(scores) / len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T13:17:31.755347Z",
     "iopub.status.busy": "2025-03-02T13:17:31.755035Z",
     "iopub.status.idle": "2025-03-02T13:17:31.759924Z",
     "shell.execute_reply": "2025-03-02T13:17:31.758973Z",
     "shell.execute_reply.started": "2025-03-02T13:17:31.755320Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Cosine Similarity: 0.9994\n"
     ]
    }
   ],
   "source": [
    "print(f\"Average Cosine Similarity: {average_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T13:19:36.836198Z",
     "iopub.status.busy": "2025-03-02T13:19:36.835837Z",
     "iopub.status.idle": "2025-03-02T13:19:36.841133Z",
     "shell.execute_reply": "2025-03-02T13:19:36.839933Z",
     "shell.execute_reply.started": "2025-03-02T13:19:36.836177Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.shuffle(paraphrased_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T13:19:47.101346Z",
     "iopub.status.busy": "2025-03-02T13:19:47.101059Z",
     "iopub.status.idle": "2025-03-02T13:20:01.464447Z",
     "shell.execute_reply": "2025-03-02T13:20:01.463586Z",
     "shell.execute_reply.started": "2025-03-02T13:19:47.101325Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c9cddbefb13455280285f6f5a7f07b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30aeb73087a14277bd1098a6e6cf9c74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embeddings_original = sbert_model.encode(original_sentences, convert_to_tensor=True)\n",
    "embeddings_paraphrased = sbert_model.encode(paraphrased_sentences, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T13:20:03.796159Z",
     "iopub.status.busy": "2025-03-02T13:20:03.795869Z",
     "iopub.status.idle": "2025-03-02T13:20:03.800641Z",
     "shell.execute_reply": "2025-03-02T13:20:03.799905Z",
     "shell.execute_reply.started": "2025-03-02T13:20:03.796137Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "cosine_scores = util.cos_sim(embeddings_original, embeddings_paraphrased)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T13:20:09.096310Z",
     "iopub.status.busy": "2025-03-02T13:20:09.096024Z",
     "iopub.status.idle": "2025-03-02T13:20:09.137278Z",
     "shell.execute_reply": "2025-03-02T13:20:09.136647Z",
     "shell.execute_reply.started": "2025-03-02T13:20:09.096288Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "scores = [cosine_scores[i][i].item() for i in range(len(original_sentences))]\n",
    "average_score = sum(scores) / len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T13:20:20.122773Z",
     "iopub.status.busy": "2025-03-02T13:20:20.122470Z",
     "iopub.status.idle": "2025-03-02T13:20:20.127013Z",
     "shell.execute_reply": "2025-03-02T13:20:20.126285Z",
     "shell.execute_reply.started": "2025-03-02T13:20:20.122749Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Cosine Similarity: 0.9927\n"
     ]
    }
   ],
   "source": [
    "print(f\"Average Cosine Similarity: {average_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T13:21:29.432169Z",
     "iopub.status.busy": "2025-03-02T13:21:29.431870Z",
     "iopub.status.idle": "2025-03-02T13:21:29.437154Z",
     "shell.execute_reply": "2025-03-02T13:21:29.436469Z",
     "shell.execute_reply.started": "2025-03-02T13:21:29.432148Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Can you provide information on optimizing investments through the use of data analytics services? I am interested in knowing which tools can assist in making informed decisions. Thanks for your assistance.'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T13:21:45.132026Z",
     "iopub.status.busy": "2025-03-02T13:21:45.131689Z",
     "iopub.status.idle": "2025-03-02T13:21:45.136890Z",
     "shell.execute_reply": "2025-03-02T13:21:45.136181Z",
     "shell.execute_reply.started": "2025-03-02T13:21:45.131997Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am writing to report that the login page is slow loading . I have tried troubleshooting by clearing my browser cache and verifying my network connection but the problem continues . I suspect the issue might be due to server overload or'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paraphrased_sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T13:22:30.091615Z",
     "iopub.status.busy": "2025-03-02T13:22:30.091284Z",
     "iopub.status.idle": "2025-03-02T13:22:30.152594Z",
     "shell.execute_reply": "2025-03-02T13:22:30.151777Z",
     "shell.execute_reply.started": "2025-03-02T13:22:30.091589Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d893cb23b087407a94c937a6209b89a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86b79d4fae814d059b66991e2ad288b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embeddings_original = sbert_model.encode(original_sentences[0], convert_to_tensor=True)\n",
    "embeddings_paraphrased = sbert_model.encode(paraphrased_sentences[0], convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T13:22:39.511038Z",
     "iopub.status.busy": "2025-03-02T13:22:39.510771Z",
     "iopub.status.idle": "2025-03-02T13:22:39.518226Z",
     "shell.execute_reply": "2025-03-02T13:22:39.517223Z",
     "shell.execute_reply.started": "2025-03-02T13:22:39.511018Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "cosine_scores = util.cos_sim(embeddings_original, embeddings_paraphrased)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T13:22:47.552775Z",
     "iopub.status.busy": "2025-03-02T13:22:47.552469Z",
     "iopub.status.idle": "2025-03-02T13:22:47.559085Z",
     "shell.execute_reply": "2025-03-02T13:22:47.558363Z",
     "shell.execute_reply.started": "2025-03-02T13:22:47.552753Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9818]], device='cuda:0')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T13:40:51.624833Z",
     "iopub.status.busy": "2025-03-02T13:40:51.624377Z",
     "iopub.status.idle": "2025-03-02T13:40:51.698102Z",
     "shell.execute_reply": "2025-03-02T13:40:51.696971Z",
     "shell.execute_reply.started": "2025-03-02T13:40:51.624799Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "253650e337b747df9f87a6e4a8cc7125",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db3f7da1b7614314803c6fa9af732928",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embeddings_original = sbert_model.encode(\"I love you\", convert_to_tensor=True)\n",
    "embeddings_paraphrased = sbert_model.encode(\"I want to buy a cookies\", convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T13:40:53.560998Z",
     "iopub.status.busy": "2025-03-02T13:40:53.560685Z",
     "iopub.status.idle": "2025-03-02T13:40:53.565293Z",
     "shell.execute_reply": "2025-03-02T13:40:53.564589Z",
     "shell.execute_reply.started": "2025-03-02T13:40:53.560972Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "cosine_scores = util.cos_sim(embeddings_original, embeddings_paraphrased)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T13:40:55.173677Z",
     "iopub.status.busy": "2025-03-02T13:40:55.173335Z",
     "iopub.status.idle": "2025-03-02T13:40:55.179792Z",
     "shell.execute_reply": "2025-03-02T13:40:55.178975Z",
     "shell.execute_reply.started": "2025-03-02T13:40:55.173652Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9061]], device='cuda:0')"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T13:29:27.311980Z",
     "iopub.status.busy": "2025-03-02T13:29:27.311664Z",
     "iopub.status.idle": "2025-03-02T13:29:27.316148Z",
     "shell.execute_reply": "2025-03-02T13:29:27.315347Z",
     "shell.execute_reply.started": "2025-03-02T13:29:27.311953Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "score = util.euclidean_sim(embeddings_original, embeddings_paraphrased)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T13:29:30.148721Z",
     "iopub.status.busy": "2025-03-02T13:29:30.148383Z",
     "iopub.status.idle": "2025-03-02T13:29:30.154281Z",
     "shell.execute_reply": "2025-03-02T13:29:30.153498Z",
     "shell.execute_reply.started": "2025-03-02T13:29:30.148695Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T13:37:20.248710Z",
     "iopub.status.busy": "2025-03-02T13:37:20.248311Z",
     "iopub.status.idle": "2025-03-02T13:37:20.320717Z",
     "shell.execute_reply": "2025-03-02T13:37:20.319914Z",
     "shell.execute_reply.started": "2025-03-02T13:37:20.248682Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdba8eac83b34136ab9f13f5fcd00044",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3912002ea0114a83b02496a3c44d1169",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Squared Euclidean Distance: 1.1294\n",
      "Euclidean Distance: 1.0627\n"
     ]
    }
   ],
   "source": [
    "vec1 = sbert_model.encode(\"I love you\", convert_to_numpy=True)\n",
    "vec2 = sbert_model.encode(\"I adore you\", convert_to_numpy=True)\n",
    "\n",
    "# squared Euclidean distance (theo cách FAISS IndexFlatL2)\n",
    "squared_euclidean_distance = np.sum((vec1 - vec2) ** 2)\n",
    "print(f\"Squared Euclidean Distance: {squared_euclidean_distance:.4f}\")\n",
    "\n",
    "euclidean_distance = np.sqrt(squared_euclidean_distance)\n",
    "print(f\"Euclidean Distance: {euclidean_distance:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T13:44:42.810274Z",
     "iopub.status.busy": "2025-03-02T13:44:42.809976Z",
     "iopub.status.idle": "2025-03-02T13:44:43.050043Z",
     "shell.execute_reply": "2025-03-02T13:44:43.049320Z",
     "shell.execute_reply.started": "2025-03-02T13:44:42.810250Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load file CSV\n",
    "df = pd.read_csv(\"/kaggle/input/multilingual-customer-support-tickets/dataset-tickets-multi-lang-4-20k.csv\")  \n",
    "\n",
    "df_english = df[df[\"language\"] == \"en\"].reset_index(drop=True)\n",
    "\n",
    "df_english = df_english[[\"answer\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T13:48:33.820069Z",
     "iopub.status.busy": "2025-03-02T13:48:33.819780Z",
     "iopub.status.idle": "2025-03-02T13:48:34.871834Z",
     "shell.execute_reply": "2025-03-02T13:48:34.870854Z",
     "shell.execute_reply.started": "2025-03-02T13:48:33.820047Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "paraphrase_pipe = pipeline(\n",
    "    \"text2text-generation\",\n",
    "    model=\"Vamsi/T5_Paraphrase_Paws\",  \n",
    "    tokenizer=\"Vamsi/T5_Paraphrase_Paws\",\n",
    "    device=0 \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T13:54:09.569183Z",
     "iopub.status.busy": "2025-03-02T13:54:09.568896Z",
     "iopub.status.idle": "2025-03-02T13:54:09.574243Z",
     "shell.execute_reply": "2025-03-02T13:54:09.573480Z",
     "shell.execute_reply.started": "2025-03-02T13:54:09.569161Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def generate_paraphrase_batch(batch):\n",
    "    print(\"Batch keys:\", list(batch.keys()))\n",
    "    sentences = batch.get(\"answer\", [])\n",
    "    if not sentences:\n",
    "        print(\"Không tìm thấy key 'answer' trong batch!\")\n",
    "    outputs = paraphrase_pipe(sentences, batch_size=len(sentences))\n",
    "    paraphrases = [out[0][\"generated_text\"] for out in outputs]\n",
    "    formatted = [\n",
    "        f\"sentence: {sent}|paraphrase: {para}\"\n",
    "        for sent, para in zip(sentences, paraphrases)\n",
    "    ]\n",
    "    return {\"formatted\": formatted}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T13:45:21.307482Z",
     "iopub.status.busy": "2025-03-02T13:45:21.307175Z",
     "iopub.status.idle": "2025-03-02T13:45:21.338753Z",
     "shell.execute_reply": "2025-03-02T13:45:21.337806Z",
     "shell.execute_reply.started": "2025-03-02T13:45:21.307457Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "dataset = Dataset.from_pandas(df_english)\n",
    "dataset = dataset.shuffle(seed=40).select(range(2000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T13:49:45.469361Z",
     "iopub.status.busy": "2025-03-02T13:49:45.469085Z",
     "iopub.status.idle": "2025-03-02T13:49:45.474279Z",
     "shell.execute_reply": "2025-03-02T13:49:45.473438Z",
     "shell.execute_reply.started": "2025-03-02T13:49:45.469339Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['answer'],\n",
       "    num_rows: 2000\n",
       "})"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T13:59:17.192257Z",
     "iopub.status.busy": "2025-03-02T13:59:17.191948Z",
     "iopub.status.idle": "2025-03-02T14:10:46.078027Z",
     "shell.execute_reply": "2025-03-02T14:10:46.077344Z",
     "shell.execute_reply.started": "2025-03-02T13:59:17.192235Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccf78ecd6ac2412883879fad8c0a25e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9da05d7f98e485cab5a79472a7a99d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1999 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence: <name> sincerely apologize for the inconvenience you are experiencing with system crashes during the analysis of investment data. We are happy to assist you in resolving this issue. Although we have already taken steps such as rebooting devices and reinstalling PowerDirector, further assistance would require gathering more information. Please provide the exact error message you receive during system crashes, along with the operating system version. Additionally, knowing your computer's processor and RAM specifications would be very helpful in narrowing down the cause of the issue.|paraphrase: Although we have already taken steps such as rebooting devices and reinstalling PowerDirector,\n"
     ]
    }
   ],
   "source": [
    "def generate_paraphrase(example):\n",
    "    sentence = example[\"answer\"]\n",
    "    output = paraphrase_pipe(sentence)[0][\"generated_text\"]\n",
    "    return {\"formatted\": f\"sentence: {sentence}|paraphrase: {output}\"}\n",
    "\n",
    "dataset = dataset.filter(lambda x: x[\"answer\"] is not None and x[\"answer\"].strip() != \"\")\n",
    "\n",
    "new_dataset = dataset.map(generate_paraphrase, batched=False)\n",
    "print(new_dataset[0][\"formatted\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T14:26:45.206294Z",
     "iopub.status.busy": "2025-03-02T14:26:45.205996Z",
     "iopub.status.idle": "2025-03-02T14:26:48.782216Z",
     "shell.execute_reply": "2025-03-02T14:26:48.781510Z",
     "shell.execute_reply.started": "2025-03-02T14:26:45.206273Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2SdpaAttention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = \"/kaggle/input/gpt2_v2/transformers/default/1\"\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained(model_path)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_path)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T14:29:17.288060Z",
     "iopub.status.busy": "2025-03-02T14:29:17.287762Z",
     "iopub.status.idle": "2025-03-02T14:29:17.294096Z",
     "shell.execute_reply": "2025-03-02T14:29:17.293432Z",
     "shell.execute_reply.started": "2025-03-02T14:29:17.288037Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def generate_paraphrase_gpt2(prompt, max_length=1024):\n",
    "    \"\"\"Sinh paraphrase từ GPT2 dựa trên prompt\"\"\"\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "    attention_mask = torch.ones(input_ids.shape, device=device) \n",
    "\n",
    "    outputs = model.generate(\n",
    "        input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        max_length=max_length,\n",
    "        num_beams=5,\n",
    "        early_stopping=True,\n",
    "        no_repeat_ngram_size=2,\n",
    "        pad_token_id=tokenizer.eos_token_id  # Thiết lập pad_token_id đúng cách\n",
    "    )\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return generated_text\n",
    "\n",
    "\n",
    "def evaluate_gpt2(example):\n",
    "    \"\"\"\n",
    "    Từ chuỗi formatted dạng:\n",
    "        \"sentence: {a sentence}|paraphrase: {a paraphrase}\"\n",
    "    Tách prompt cho GPT2 và ground truth.\n",
    "    \"\"\"\n",
    "    formatted = example[\"formatted\"]\n",
    "    try:\n",
    "        prompt_part, reference = formatted.split(\"|paraphrase:\")\n",
    "    except Exception as e:\n",
    "        prompt_part, reference = formatted, \"\"\n",
    "    prompt = prompt_part + \"|paraphrase:\"\n",
    "    reference = reference.strip()\n",
    "    \n",
    "    output = generate_paraphrase_gpt2(prompt)\n",
    "    \n",
    "    return {\"gpt2_output\": output, \"reference\": reference}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T14:29:20.055899Z",
     "iopub.status.busy": "2025-03-02T14:29:20.055624Z",
     "iopub.status.idle": "2025-03-02T14:50:34.746275Z",
     "shell.execute_reply": "2025-03-02T14:50:34.745172Z",
     "shell.execute_reply.started": "2025-03-02T14:29:20.055878Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9487cab9fd794b58abea10e17c8d89fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1999 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'evaluate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-148-cc59104c30e1>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# 5. Đánh giá với metric BLEU từ thư viện evaluate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mbleu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bleu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"gpt2_output\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0meval_dataset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mreferences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"reference\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0meval_dataset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'evaluate' is not defined"
     ]
    }
   ],
   "source": [
    "eval_dataset = new_dataset.map(evaluate_gpt2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T14:58:08.579888Z",
     "iopub.status.busy": "2025-03-02T14:58:08.579593Z",
     "iopub.status.idle": "2025-03-02T14:58:09.334154Z",
     "shell.execute_reply": "2025-03-02T14:58:09.333223Z",
     "shell.execute_reply.started": "2025-03-02T14:58:08.579866Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample predictions: [['sentence:', '<name>', 'sincerely', 'apologize', 'for', 'the', 'inconvenience', 'you', 'are', 'experiencing', 'with', 'system', 'crashes', 'during', 'the', 'analysis', 'of', 'investment', 'data.', 'We', 'are', 'happy', 'to', 'assist', 'you', 'in', 'resolving', 'this', 'issue.', 'Although', 'we', 'have', 'already', 'taken', 'steps', 'such', 'as', 'rebooting', 'devices', 'and', 'reinstalling', 'PowerDirector,', 'further', 'assistance', 'would', 'require', 'gathering', 'more', 'information.', 'Please', 'provide', 'the', 'exact', 'error', 'message', 'you', 'receive', 'during', 'system', 'crashes,', 'along', 'with', 'the', 'operating', 'system', 'version.', 'Additionally,', 'knowing', 'your', \"computer's\", 'processor', 'and', 'RAM', 'specifications', 'would', 'be', 'very', 'helpful', 'in', 'narrowing', 'down', 'the', 'cause', 'of', 'the', 'issue.|paraphrase:', 'name>', 'is', 'sincerely', 'apologetic', 'and', 'sincerely', 'sorry', 'for', 'this', 'inconvenience', 'caused', 'by', 'the', 'system', 'crash', 'of', 'your', 'system', '.', 'We', 'will', 'work', 'to', 'resolve', 'this', 'problem', 'as', 'soon', 'as', 'possible', '.', 'However,', 'it', 'is', 'possible', 'that', 'we', 'may', 'need', 'to', 'gather', 'additional', 'information', 'from', 'you', 'to', 'further', 'help', 'you', '.', 'If', 'you', 'wish', 'to', 'discuss', 'this', 'further,', 'please', 'let', 'us', 'know', 'a', 'convenient', 'time', 'for', 'a', 'call.'], ['sentence:', 'I', 'will', 'draft', 'an', 'email', 'acknowledging', 'the', 'underperformance', 'of', 'the', 'digital', 'marketing', 'strategies.', 'To', 'better', 'understand', 'the', 'issue,', 'please', 'provide', 'information', 'on', 'the', 'target', 'audience', 'and', 'the', 'current', 'digital', 'tactics', 'being', 'used.', 'Additionally,', 'please', 'share', 'specific', 'metrics', 'that', 'indicate', 'the', 'limited', 'improvement.', 'This', 'will', 'help', 'us', 'provide', 'an', 'accurate', 'assessment', 'and', 'potential', 'solutions', 'to', 'realign', 'the', 'digital', 'marketing', 'efforts', 'with', 'the', 'brand', 'growth', 'goals.', 'I', 'am', 'available', 'to', 'schedule', 'a', 'call', 'at', 'your', 'convenience', 'to', 'discuss', 'this', 'further.|paraphrase:', 'If', 'I', 'can', 'provide', 'you', 'with', 'information', 'about', 'the', 'performance', 'of', 'digital', 'strategies,', 'it', 'would', 'be', 'helpful', 'to', 'know', 'which', 'metrics', 'indicate', 'that', 'the', 'reduced', 'engagement', 'has', 'been', 'due', 'to', 'underperforming', 'the', 'targeted', 'audience', 'or', 'current', 'tactics', 'used', '.', 'This', 'information', 'will', 'assist', 'me', 'in', 'better', 'understanding', 'the', 'problem', 'and', 'to', 'identify', 'the', 'root', 'cause', '.', 'If', 'you', 'have', 'any', 'further', 'questions', 'or', 'concerns,', 'feel', 'free', 'to', 'reach', 'out', 'to', 'me.'], ['sentence:', 'I', 'will', 'provide', 'detailed', 'information', 'on', 'integration', 'capabilities', 'via', 'the', 'next', 'email', 'for', 'your', 'convenience,', 'and', 'we', 'can', 'discuss', 'further.|paraphrase:', 'To', 'provide', 'details', 'on', 'integrating', 'capabilities', 'with', 'IFTTT,', 'please', 'provide', 'specific', 'information', 'about', 'your', 'current', 'setup', 'and', 'any', 'upcoming', 'updates.']]\n",
      "Sample references: [[['Although', 'we', 'have', 'already', 'taken', 'steps', 'such', 'as', 'rebooting', 'devices', 'and', 'reinstalling', 'PowerDirector,']], [['I', 'will', 'draft', 'an', 'email', 'acknowledging', 'the', 'underperformance', 'of', 'the', 'digital', 'marketing', 'strategies', '.', 'To', 'better', 'understand']], [['For', 'your', 'convenience,', 'I', 'will', 'provide', 'detailed', 'information', 'on', 'integration', 'capabilities', 'via', 'the', 'next', 'email', 'and', 'we', 'can', 'discuss']]]\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "\n",
    "print(\"Sample predictions:\", predictions[:3])\n",
    "print(\"Sample references:\", references[:3])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T15:00:35.097957Z",
     "iopub.status.busy": "2025-03-02T15:00:35.097658Z",
     "iopub.status.idle": "2025-03-02T15:00:35.107770Z",
     "shell.execute_reply": "2025-03-02T15:00:35.106949Z",
     "shell.execute_reply.started": "2025-03-02T15:00:35.097935Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "predictions = [\" \".join(pred) if isinstance(pred, list) else pred for pred in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T15:00:36.605674Z",
     "iopub.status.busy": "2025-03-02T15:00:36.605334Z",
     "iopub.status.idle": "2025-03-02T15:00:36.611279Z",
     "shell.execute_reply": "2025-03-02T15:00:36.610254Z",
     "shell.execute_reply.started": "2025-03-02T15:00:36.605647Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "references = [[\" \".join(ref[0])] if isinstance(ref[0], list) else [\" \".join(ref)] for ref in references]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T15:01:48.839550Z",
     "iopub.status.busy": "2025-03-02T15:01:48.839235Z",
     "iopub.status.idle": "2025-03-02T15:01:52.205565Z",
     "shell.execute_reply": "2025-03-02T15:01:52.204458Z",
     "shell.execute_reply.started": "2025-03-02T15:01:48.839528Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.2.4)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from nltk) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T15:02:04.304740Z",
     "iopub.status.busy": "2025-03-02T15:02:04.304352Z",
     "iopub.status.idle": "2025-03-02T15:02:04.831107Z",
     "shell.execute_reply": "2025-03-02T15:02:04.830413Z",
     "shell.execute_reply.started": "2025-03-02T15:02:04.304710Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "predictions = [\" \".join(pred) if isinstance(pred, list) else pred for pred in predictions]\n",
    "references = [[\" \".join(ref[0])] if isinstance(ref[0], list) else [ref] for ref in references]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T15:03:05.561822Z",
     "iopub.status.busy": "2025-03-02T15:03:05.561488Z",
     "iopub.status.idle": "2025-03-02T15:03:05.567889Z",
     "shell.execute_reply": "2025-03-02T15:03:05.567016Z",
     "shell.execute_reply.started": "2025-03-02T15:03:05.561799Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Nếu references có mức lồng thừa, chuyển thành list[list[str]]\n",
    "references = [[ \" \".join(ref[0]) ] if isinstance(ref[0], list) else [ref] for ref in references]\n",
    "\n",
    "# Nếu predictions vẫn là list từ, gộp lại thành câu\n",
    "predictions = [\" \".join(pred) if isinstance(pred, list) else pred for pred in predictions]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T15:03:18.761937Z",
     "iopub.status.busy": "2025-03-02T15:03:18.761639Z",
     "iopub.status.idle": "2025-03-02T15:03:18.767352Z",
     "shell.execute_reply": "2025-03-02T15:03:18.766558Z",
     "shell.execute_reply.started": "2025-03-02T15:03:18.761914Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample predictions: [\"sentence: <name> sincerely apologize for the inconvenience you are experiencing with system crashes during the analysis of investment data. We are happy to assist you in resolving this issue. Although we have already taken steps such as rebooting devices and reinstalling PowerDirector, further assistance would require gathering more information. Please provide the exact error message you receive during system crashes, along with the operating system version. Additionally, knowing your computer's processor and RAM specifications would be very helpful in narrowing down the cause of the issue.|paraphrase: name> is sincerely apologetic and sincerely sorry for this inconvenience caused by the system crash of your system . We will work to resolve this problem as soon as possible . However, it is possible that we may need to gather additional information from you to further help you . If you wish to discuss this further, please let us know a convenient time for a call.\", 'sentence: I will draft an email acknowledging the underperformance of the digital marketing strategies. To better understand the issue, please provide information on the target audience and the current digital tactics being used. Additionally, please share specific metrics that indicate the limited improvement. This will help us provide an accurate assessment and potential solutions to realign the digital marketing efforts with the brand growth goals. I am available to schedule a call at your convenience to discuss this further.|paraphrase: If I can provide you with information about the performance of digital strategies, it would be helpful to know which metrics indicate that the reduced engagement has been due to underperforming the targeted audience or current tactics used . This information will assist me in better understanding the problem and to identify the root cause . If you have any further questions or concerns, feel free to reach out to me.', 'sentence: I will provide detailed information on integration capabilities via the next email for your convenience, and we can discuss further.|paraphrase: To provide details on integrating capabilities with IFTTT, please provide specific information about your current setup and any upcoming updates.']\n",
      "Sample references: [['Although we have already taken steps such as rebooting devices and reinstalling PowerDirector,'], ['I will draft an email acknowledging the underperformance of the digital marketing strategies . To better understand'], ['For your convenience, I will provide detailed information on integration capabilities via the next email and we can discuss']]\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample predictions:\", predictions[:3])\n",
    "print(\"Sample references:\", references[:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T15:04:42.590970Z",
     "iopub.status.busy": "2025-03-02T15:04:42.590639Z",
     "iopub.status.idle": "2025-03-02T15:04:43.149002Z",
     "shell.execute_reply": "2025-03-02T15:04:43.148267Z",
     "shell.execute_reply.started": "2025-03-02T15:04:42.590947Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample tokenized predictions: [['sentence:', '<name>', 'sincerely', 'apologize', 'for', 'the', 'inconvenience', 'you', 'are', 'experiencing', 'with', 'system', 'crashes', 'during', 'the', 'analysis', 'of', 'investment', 'data.', 'We', 'are', 'happy', 'to', 'assist', 'you', 'in', 'resolving', 'this', 'issue.', 'Although', 'we', 'have', 'already', 'taken', 'steps', 'such', 'as', 'rebooting', 'devices', 'and', 'reinstalling', 'PowerDirector,', 'further', 'assistance', 'would', 'require', 'gathering', 'more', 'information.', 'Please', 'provide', 'the', 'exact', 'error', 'message', 'you', 'receive', 'during', 'system', 'crashes,', 'along', 'with', 'the', 'operating', 'system', 'version.', 'Additionally,', 'knowing', 'your', \"computer's\", 'processor', 'and', 'RAM', 'specifications', 'would', 'be', 'very', 'helpful', 'in', 'narrowing', 'down', 'the', 'cause', 'of', 'the', 'issue.|paraphrase:', 'name>', 'is', 'sincerely', 'apologetic', 'and', 'sincerely', 'sorry', 'for', 'this', 'inconvenience', 'caused', 'by', 'the', 'system', 'crash', 'of', 'your', 'system', '.', 'We', 'will', 'work', 'to', 'resolve', 'this', 'problem', 'as', 'soon', 'as', 'possible', '.', 'However,', 'it', 'is', 'possible', 'that', 'we', 'may', 'need', 'to', 'gather', 'additional', 'information', 'from', 'you', 'to', 'further', 'help', 'you', '.', 'If', 'you', 'wish', 'to', 'discuss', 'this', 'further,', 'please', 'let', 'us', 'know', 'a', 'convenient', 'time', 'for', 'a', 'call.'], ['sentence:', 'I', 'will', 'draft', 'an', 'email', 'acknowledging', 'the', 'underperformance', 'of', 'the', 'digital', 'marketing', 'strategies.', 'To', 'better', 'understand', 'the', 'issue,', 'please', 'provide', 'information', 'on', 'the', 'target', 'audience', 'and', 'the', 'current', 'digital', 'tactics', 'being', 'used.', 'Additionally,', 'please', 'share', 'specific', 'metrics', 'that', 'indicate', 'the', 'limited', 'improvement.', 'This', 'will', 'help', 'us', 'provide', 'an', 'accurate', 'assessment', 'and', 'potential', 'solutions', 'to', 'realign', 'the', 'digital', 'marketing', 'efforts', 'with', 'the', 'brand', 'growth', 'goals.', 'I', 'am', 'available', 'to', 'schedule', 'a', 'call', 'at', 'your', 'convenience', 'to', 'discuss', 'this', 'further.|paraphrase:', 'If', 'I', 'can', 'provide', 'you', 'with', 'information', 'about', 'the', 'performance', 'of', 'digital', 'strategies,', 'it', 'would', 'be', 'helpful', 'to', 'know', 'which', 'metrics', 'indicate', 'that', 'the', 'reduced', 'engagement', 'has', 'been', 'due', 'to', 'underperforming', 'the', 'targeted', 'audience', 'or', 'current', 'tactics', 'used', '.', 'This', 'information', 'will', 'assist', 'me', 'in', 'better', 'understanding', 'the', 'problem', 'and', 'to', 'identify', 'the', 'root', 'cause', '.', 'If', 'you', 'have', 'any', 'further', 'questions', 'or', 'concerns,', 'feel', 'free', 'to', 'reach', 'out', 'to', 'me.'], ['sentence:', 'I', 'will', 'provide', 'detailed', 'information', 'on', 'integration', 'capabilities', 'via', 'the', 'next', 'email', 'for', 'your', 'convenience,', 'and', 'we', 'can', 'discuss', 'further.|paraphrase:', 'To', 'provide', 'details', 'on', 'integrating', 'capabilities', 'with', 'IFTTT,', 'please', 'provide', 'specific', 'information', 'about', 'your', 'current', 'setup', 'and', 'any', 'upcoming', 'updates.']]\n",
      "Sample tokenized references: [[['Although', 'we', 'have', 'already', 'taken', 'steps', 'such', 'as', 'rebooting', 'devices', 'and', 'reinstalling', 'PowerDirector,']], [['I', 'will', 'draft', 'an', 'email', 'acknowledging', 'the', 'underperformance', 'of', 'the', 'digital', 'marketing', 'strategies', '.', 'To', 'better', 'understand']], [['For', 'your', 'convenience,', 'I', 'will', 'provide', 'detailed', 'information', 'on', 'integration', 'capabilities', 'via', 'the', 'next', 'email', 'and', 'we', 'can', 'discuss']]]\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "# Tokenize predictions\n",
    "tokenized_predictions = [pred.split() for pred in predictions]  # list[list[str]]\n",
    "\n",
    "# Tokenize references (phải là list[list[list[str]]])\n",
    "tokenized_references = [[ref[0].split()] for ref in references]  # list[list[list[str]]]\n",
    "\n",
    "# Kiểm tra lại dữ liệu\n",
    "print(\"Sample tokenized predictions:\", tokenized_predictions[:3])\n",
    "print(\"Sample tokenized references:\", tokenized_references[:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T15:05:06.197037Z",
     "iopub.status.busy": "2025-03-02T15:05:06.196732Z",
     "iopub.status.idle": "2025-03-02T15:05:07.049807Z",
     "shell.execute_reply": "2025-03-02T15:05:07.048923Z",
     "shell.execute_reply.started": "2025-03-02T15:05:06.197014Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score: 0.1179\n"
     ]
    }
   ],
   "source": [
    "bleu_score = corpus_bleu(tokenized_references, tokenized_predictions)\n",
    "\n",
    "print(f\"BLEU Score: {bleu_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T15:21:40.493842Z",
     "iopub.status.busy": "2025-03-02T15:21:40.493500Z",
     "iopub.status.idle": "2025-03-02T15:21:44.995741Z",
     "shell.execute_reply": "2025-03-02T15:21:44.994984Z",
     "shell.execute_reply.started": "2025-03-02T15:21:40.493816Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE-1: 0.3071\n",
      "ROUGE-2: 0.2844\n",
      "ROUGE-L: 0.3017\n"
     ]
    }
   ],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "\n",
    "rouge_scores = [scorer.score(pred, ref[0]) for pred, ref in zip(predictions, references)]\n",
    "\n",
    "rouge1 = sum(score['rouge1'].fmeasure for score in rouge_scores) / len(rouge_scores)\n",
    "rouge2 = sum(score['rouge2'].fmeasure for score in rouge_scores) / len(rouge_scores)\n",
    "rougeL = sum(score['rougeL'].fmeasure for score in rouge_scores) / len(rouge_scores)\n",
    "\n",
    "print(f\"ROUGE-1: {rouge1:.4f}\")\n",
    "print(f\"ROUGE-2: {rouge2:.4f}\")\n",
    "print(f\"ROUGE-L: {rougeL:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T15:26:14.838759Z",
     "iopub.status.busy": "2025-03-02T15:26:14.838344Z",
     "iopub.status.idle": "2025-03-02T15:26:42.508602Z",
     "shell.execute_reply": "2025-03-02T15:26:42.507643Z",
     "shell.execute_reply.started": "2025-03-02T15:26:14.838731Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity (PPL): 4.8845\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "# Load lại model và tokenizer\n",
    "model.eval()\n",
    "def calculate_perplexity(text):\n",
    "    encodings = tokenizer(text, return_tensors=\"pt\")\n",
    "    input_ids = encodings.input_ids.to(\"cuda\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, labels=input_ids)\n",
    "        loss = outputs.loss\n",
    "        perplexity = torch.exp(loss).item()\n",
    "    \n",
    "    return perplexity\n",
    "\n",
    "# Tính perplexity trung bình\n",
    "ppl_scores = [calculate_perplexity(pred) for pred in predictions]\n",
    "average_ppl = sum(ppl_scores) / len(ppl_scores)\n",
    "\n",
    "print(f\"Perplexity (PPL): {average_ppl:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5268504,
     "sourceId": 10667702,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 255305,
     "modelInstanceId": 233584,
     "sourceId": 272815,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 255353,
     "modelInstanceId": 233633,
     "sourceId": 272871,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
